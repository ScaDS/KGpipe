# Inc Movie KG

Documentation and experiment code for incremental KG generation and evaluation.


# Dataset Overview

- ðŸ“Š [Benchmark Datasets](https://doi.org/10.5281/zenodo.17246357)

A benchmark derived from Wikipedia and DBpedia in the movie domain covering the three entities: `Film,Person,Company` described and connected by 23(+2) attributes.
The dataset consists of the following.

Four Splits and three different formats:
- RDF: RDF from DBpedia, in the three namespaces for seed, reference and source data
- JSON: json files built from the tree like subgraphs of each film
- TEXT: abstract text of each film entity from wikipedia

Suplmenetary data:
- reference entity matches: for entity matching eval (rdf, json)
- reference entity links: for entity linking eval (text)
- provannce mappings: for tracing json entity mappings
- refernce key mappings: for tracing json to rdf schema matching

Available in three sizes:
- small 100 films: for development
- medium 1,000 films: for testing
- large 10,000 films: for benchmarking

# Running

It is possible to execute the experiemnt in a docker environment.
Adapt the `docker.env` file 
and choose the dataset size (small, medium, large)

> LLM tasks are disabled by default to enable them add
> make pipelines-llm as task in [moviekg_docker.sh](../../scripts/moviekg_docker.sh)

Prepare
```
make setup_docker
```

Execution of dataset stats, pipelines, evalaution, and paper content generation
```
make run_docker_small
```

For more detailed information see also [reproduce.md](../../docs/reproduce.md) or [docs](../../docs/)

# Directory Structure

## Input Structure

```
â”œâ”€â”€ film_100
â”‚Â Â  â”œâ”€â”€ entities
â”‚Â Â  â”‚Â Â  â””â”€â”€ master_entities.csv
â”‚Â Â  â”œâ”€â”€ ontology.ttl -> ../movie-ontology.ttl
â”‚Â Â  â”œâ”€â”€ split_0
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ index
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ entities.csv
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ kg
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ reference
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ data/
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ data_agg.nt
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ data.nt
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ meta/
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ seed
â”‚Â Â  â”‚Â Â  â”‚Â Â      â”œâ”€â”€ data/
â”‚Â Â  â”‚Â Â  â”‚Â Â      â”œâ”€â”€ data.nt
â”‚Â Â  â”‚Â Â  â”‚Â Â      â””â”€â”€ meta/
â”‚Â Â  â”‚Â Â  â””â”€â”€ sources
â”‚Â Â  â”‚Â Â      â”œâ”€â”€ json
â”‚Â Â  â”‚Â Â      â”‚Â Â  â”œâ”€â”€ data/
â”‚Â Â  â”‚Â Â      â”‚Â Â  â””â”€â”€ meta/
â”‚Â Â  â”‚Â Â      â”œâ”€â”€ rdf
â”‚Â Â  â”‚Â Â      â”‚Â Â  â”œâ”€â”€ data/
â”‚Â Â  â”‚Â Â      â”‚Â Â  â”œâ”€â”€ data.nt
â”‚Â Â  â”‚Â Â      â”‚Â Â  â””â”€â”€ meta/
â”‚Â Â  â”‚Â Â      â””â”€â”€ text
â”‚Â Â  â”‚Â Â          â”œâ”€â”€ data/
â”‚Â Â  â”‚Â Â          â””â”€â”€ meta/
â”‚Â Â  â”œâ”€â”€ split_1[... trunc]
â”œâ”€â”€ film_1k[... trunc]
```

## Output Structure

```
â”œâ”€â”€ small
â”‚Â Â  â”œâ”€â”€ all_metrics.csv
â”‚Â Â  â”œâ”€â”€ json_a
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ stage_1
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ exec-plan.json
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ exec-report.json
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ result.nt
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ tmp/
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ stage_2
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ exec-plan.json
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ exec-report.json
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ result.nt
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ tmp/
â”‚Â Â  â”‚Â Â  â””â”€â”€ stage_3
â”‚Â Â  â”‚Â Â      â”œâ”€â”€ exec-plan.json
â”‚Â Â  â”‚Â Â      â”œâ”€â”€ exec-report.json
â”‚Â Â  â”‚Â Â      â”œâ”€â”€ result.nt
â”‚Â Â  â”‚Â Â      â””â”€â”€ tmp/
â”‚   â”œâ”€â”€ json_b[... trunc]
â”‚Â Â  â”œâ”€â”€ paper
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ test_fig....png
â”‚Â Â  â”‚Â Â  â””â”€â”€ test_tab.....png
â””â”€â”€ medium[... trunc]
```